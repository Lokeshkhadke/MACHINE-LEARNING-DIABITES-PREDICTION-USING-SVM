# -*- coding: utf-8 -*-
"""Customer Segmentation.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1CfIfHUnB-XSqpevolS2_nCfWI1Cmlpe2

**Introduction**

This project utilizes the **K-Means Clustering **algorithm to **segment customers** **based on their Annual Income and Spending Score**from a mall dataset.

Goal is to identify distinct customer groups that can be targeted with specific marketing strategies or business insights. We will preprocess the data, determine the optimal number of clusters, apply the K-Means algorithm, visualize the results, and interpret the clusters.
"""

pip install kneed

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler
from sklearn.cluster import KMeans
from sklearn.preprocessing import LabelEncoder
from kneed import KneeLocator

"""**Here NumPy and Pandas** are used for** data manipulation and handling.**

**Matplotlib and Seaborn **are for creating visualizations.

**StandardScaler** helps **scale the features **to ensure all features contribute equally to the clustering.

**LabelEncoder** is used to **convert categorical values (like Gender) to numerical values.**

**KMeans** is the **clustering algorithm** that will be used to divide customers into groups.

**KneeLocator** helps identify the **"elbow"** point in the WCSS (Within-Cluster Sum of Squares) graph **to find the optimal number of clusters.**

**IMPORTING THE DATASET**
"""

data = pd.read_csv('/content/Mall_Customers.csv')
print(data)

"""**TO DISPLAY FIRST FEW ROWS OF THE DATA STRUCTURE**"""

data.head()

"""**TO DISPLAY LAST FEW ROWS OF THE DATA STRUCTURE**"""

data.tail()

"""**TO FIND NUMBER OF ROWS AND COLUMNS**"""

data.shape

"""**TO PROVIDE STATISTICAL SUMMAIRES OF DATA STRUCTURE**"""

data.describe()

"""**DISPLAY BASIC INFORMATION ABOUT THE COLUMNS INCLUDING DATATYPES.**"""

data.info()

"""**CHECK FOR ANY NULL VALUES TO ENUSRE DATA QUALITY**"""

data.isnull().sum()

"""**to Encode categorical columns like Gender **


beacuse without encoding of feature column gender into float it is not possible to calculate the correlation values unless all the values are numerical.

The Gender column is encoded from text ('Male'/'Female') into numerical values (0/1) because most machine learning algorithms, including K-Means, require numerical input.


The LabelEncoder converts 'Male' to 1 and 'Female' to 0.

ThE below matrix helps to identify relationships between features, guiding us to choose relevant features for clustering.
"""

# Encode categorical columns like Gender
data['Gender'] = LabelEncoder().fit_transform(data['Gender'])

# Re-generate heatmap
plt.figure(figsize=(6, 4))
sns.heatmap(data.corr(), annot=True, cmap='plasma')
plt.title('Feature Correlation Matrix (with Encoded Gender)')
plt.show()

"""**SELECTING FEATURES FOR CLUSTERING**

Choosing the Annual Income Column & Spending Score column
"""

X = data.iloc[:,[3,4]].values
print(X)

# Scaling the data
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
print("Scaled Data:")
print(X_scaled)

"""StandardScaler is used to scale the features (Annual Income and Spending Score).

Scaling ensures both features have the same scale (mean of 0, standard deviation of 1).

This is important for K-Means, as the algorithm uses distance calculations (Euclidean distance) between points, and unscaled data could bias the clustering process.

**FINDING THE OPTIMUM NUMBER OF CLUSTERS USING ELBOW METHOD**
"""

# finding wcss(Within-Cluster Sum of Squares) value for different number of clusters

wcss = []

for i in range(1,11):
  kmeans = KMeans(n_clusters=i, init='k-means++', random_state=42)
  kmeans.fit(X)

  wcss.append(kmeans.inertia_)

#Elbow graph

sns.set()
plt.plot(range(1,11), wcss)
plt.title('The Elbow Point Graph')
plt.xlabel('Number of Clusters')
plt.ylabel('WCSS')
plt.show()

# Optimal number of clusters using KneeLocator
knee = KneeLocator(range(1, 11), wcss, curve="convex", direction="decreasing")
optimal_clusters = knee.knee
print(f"Optimal number of clusters: {optimal_clusters}")

"""From the graph, it is seen that the optimum number of clusters is 5. To cross-validate this, the above method using the "kneedle" technique was applied for verification.

Next, the k-Means Clustering model is being trained.

**TRAINING THE K-MEANS MODEL**
"""

kmeans = KMeans(n_clusters=5, init='k-means++', random_state=0)

# return a label for each data point based on their cluster
Y = kmeans.fit_predict(X)

print(Y)

"""There are 5 Clusters -  0, 1, 2, 3, 4"""

# plotting all the clusters and their Centroids

plt.figure(figsize=(8,8))
plt.scatter(X[Y==0,0], X[Y==0,1], s=50, c='#FF6F61', label='Cluster 1')
plt.scatter(X[Y==1,0], X[Y==1,1], s=50, c='#6B5B95', label='Cluster 2')
plt.scatter(X[Y==2,0], X[Y==2,1], s=50, c='#88B04B', label='Cluster 3')
plt.scatter(X[Y==3,0], X[Y==3,1], s=50, c='#F7CAC9', label='Cluster 4')
plt.scatter(X[Y==4,0], X[Y==4,1], s=50, c='#92A8D1', label='Cluster 5')

# plot the centroids
plt.scatter(kmeans.cluster_centers_[:,0], kmeans.cluster_centers_[:,1], s=100, c='#FFD700', label='Centroids')

plt.title('Customer Groups')
plt.xlabel('Annual Income')
plt.ylabel('Spending Score')
plt.show()

"""**PROFILING EACH CLUSTER AND PLOTTING OTHER PLOT**"""

# Cluster Profiles
data = data.copy()
data['Cluster'] = Y
for i in range(optimal_clusters):
    print(f"\nCluster {i} Statistics:")
    print(data[data['Cluster'] == i].describe())


# Optional plot: Interactive Visualization using Plotly
import plotly.express as px
fig = px.scatter(data, x='Annual Income (k$)', y='Spending Score (1-100)',
                 color=Y.astype(str), title='Clusters of Customers',
                 labels={'color': 'Cluster'})
fig.show()

"""**CONCLUSION :**

This project successfully segments customers into 5 distinct groups based on Annual Income and Spending Score using K-Means Clustering. By profiling these clusters, we gain valuable insights into customer behavior, which can be useful for targeted marketing and customer engagement strategies. The optimal number of clusters was determined using both the Elbow Method and KneeLocator for accuracy. The final model has been saved and can be reused for future predictions or insights.
"""